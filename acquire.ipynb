{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Codeup Blog Articles\n",
    "\n",
    "Scrape the article text from the following pages:\n",
    "\n",
    "- https://codeup.com/codeups-data-science-career-accelerator-is-here/\n",
    "\n",
    "- https://codeup.com/data-science-myths/\n",
    "\n",
    "- https://codeup.com/data-science-vs-data-analytics-whats-the-difference/\n",
    "\n",
    "- https://codeup.com/10-tips-to-crush-it-at-the-sa-tech-job-fair/\n",
    "\n",
    "- https://codeup.com/competitor-bootcamps-are-closing-is-the-model-in-danger/\n",
    "\n",
    "Encapsulate your work in a function named `get_blog_articles` that will return a list of dictionaries, with each dictionary representing one article. The shape of each dictionary should look like this:\n",
    "\n",
    "```python\n",
    "{\n",
    "    'title': 'the title of the article',\n",
    "    'content': 'the full text content of the article'\n",
    "}```\n",
    "\n",
    "Plus any additional properties you think might be helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://codeup.com/codeups-data-science-career-accelerator-is-here/'\n",
    "headers = {'User-Agent': 'Codeup Data Science'} \n",
    "response = get(url, headers=headers)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html><html lang=\"en-US\"><head >\t<meta charset=\"UTF-8\" />\n",
      "\t<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" />\n",
      "\t\n",
      "\t<!-- This site is optimized with the Yoast SEO plugin v15.2 - https://yoast.com/wordpress/plugins/seo/ -->\n",
      "\t<title>Codeup’s Data Science Career Accelerator is Here! - Codeup</title>\n",
      "\t<meta name=\"description\" content=\"The rumors are true! The time has arrived\n"
     ]
    }
   ],
   "source": [
    "print(response.text[:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The rumors are true! The time has arrived. Codeup has officially opened applications to our new Data Science career accelerator, with only 25 seats available! This immersive program is one of a kind in San Antonio, and will help you land a job in\\xa0Glassdoor’s #1 Best Job in America.\\nData Science is a method of providing actionable intelligence from data.\\xa0The data revolution has hit San Antonio,\\xa0resulting in an explosion in Data Scientist positions\\xa0across companies like USAA, Accenture, Booz Allen Hamilton, and HEB. We’ve even seen\\xa0UTSA invest $70 M for a Cybersecurity Center and School of Data Science.\\xa0We built a program to specifically meet the growing demands of this industry.\\nOur program will be 18 weeks long, full-time, hands-on, and project-based. Our curriculum development and instruction is led by Senior Data Scientist, Maggie Giust, who has worked at HEB, Capital Group, and Rackspace, along with input from dozens of practitioners and hiring partners. Students will work with real data sets, realistic problems, and the entire data science pipeline from collection to deployment. They will receive professional development training in resume writing, interviewing, and continuing education to prepare for a smooth transition to the workforce.\\nWe focus on applied data science for immediate impact and ROI in a business, which is how we can back it all up with a 6 month tuition refund guarantee – just like our existing Web Dev program. We’re focusing on Data Science with Python, SQL, and ML, covered in\\xa014 modules: 1) Fundamentals; 2) Applied statistics; 3) SQL; 4) Python; 5) Supervised machine learning – regression; 6) Supervised machine learning – classification; 7) Unsupervised machine learning – clustering; 8) Time series analysis; 9) Anomaly detection; 10) Natural language processing; 11) Distributed machine learning; 12) Advanced topics (deep learning, NoSQL, cloud deployment, etc.); 13) Storytelling with data; and 14) Domain expertise development.\\nApplications are now open\\xa0for Codeup’s first Data Science cohort, which will start class on February 4, 2019. Hurry – there are only 25 seats available! To further our mission of cultivating inclusive growth, scholarships will be available to women, minorities, LGBTQIA+ individuals, veterans, first responders, and people relocating to San Antonio.\\nIf you want to learn about joining our program or hiring our graduates, email datascience@codeup.com!\\n\\n'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article = soup.find('div', class_='jupiterx-post-content')\n",
    "article.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('article.txt', 'w') as f:\n",
    "    f.write(article.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article_text():\n",
    "    # if we already have the data, read it locally\n",
    "    if os.path.exists('article.txt'):\n",
    "        with open('article.txt') as f:\n",
    "            return f.read()\n",
    "\n",
    "    # otherwise go fetch the data\n",
    "    url = 'https://codeup.com/codeups-data-science-career-accelerator-is-here/'\n",
    "    headers = {'User-Agent': 'Codeup Data Science'}\n",
    "    response = get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.text)\n",
    "    article = soup.find('div', class_='jupiterx-post-content')\n",
    "\n",
    "    # save it for next time\n",
    "    with open('article.txt', 'w') as f:\n",
    "        f.write(article.text)\n",
    "\n",
    "    return article.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The rumors are true! The time has arrived. Codeup has officially opened applications to our new Data Science career accelerator, with only 25 seats available! This immersive program is one of a kind in San Antonio, and will help you land a job in\\xa0Glassdoor’s #1 Best Job in America.\\nData Science is a method of providing actionable intelligence from data.\\xa0The data revolution has hit San Antonio,\\xa0resulting in an explosion in Data Scientist positions\\xa0across companies like USAA, Accenture, Booz Allen Hamilton, and HEB. We’ve even seen\\xa0UTSA invest $70 M for a Cybersecurity Center and School of Data Science.\\xa0We built a program to specifically meet the growing demands of this industry.\\nOur program will be 18 weeks long, full-time, hands-on, and project-based. Our curriculum development and instruction is led by Senior Data Scientist, Maggie Giust, who has worked at HEB, Capital Group, and Rackspace, along with input from dozens of practitioners and hiring partners. Students will work with real data sets, realistic problems, and the entire data science pipeline from collection to deployment. They will receive professional development training in resume writing, interviewing, and continuing education to prepare for a smooth transition to the workforce.\\nWe focus on applied data science for immediate impact and ROI in a business, which is how we can back it all up with a 6 month tuition refund guarantee – just like our existing Web Dev program. We’re focusing on Data Science with Python, SQL, and ML, covered in\\xa014 modules: 1) Fundamentals; 2) Applied statistics; 3) SQL; 4) Python; 5) Supervised machine learning – regression; 6) Supervised machine learning – classification; 7) Unsupervised machine learning – clustering; 8) Time series analysis; 9) Anomaly detection; 10) Natural language processing; 11) Distributed machine learning; 12) Advanced topics (deep learning, NoSQL, cloud deployment, etc.); 13) Storytelling with data; and 14) Domain expertise development.\\nApplications are now open\\xa0for Codeup’s first Data Science cohort, which will start class on February 4, 2019. Hurry – there are only 25 seats available! To further our mission of cultivating inclusive growth, scholarships will be available to women, minorities, LGBTQIA+ individuals, veterans, first responders, and people relocating to San Antonio.\\nIf you want to learn about joining our program or hiring our graduates, email datascience@codeup.com!\\n\\n'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_article_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bonus**:\n",
    "\n",
    "- Scrape the text of all the articles linked on codeup's blog page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. News Articles\n",
    "\n",
    "We will now be scraping text data from inshorts, a website that provides a brief overview of many different topics.\n",
    "\n",
    "Write a function that scrapes the news articles for the following topics:\n",
    "\n",
    "- Business\n",
    "- Sports\n",
    "- Technology\n",
    "- Entertainment\n",
    "The end product of this should be a function named `get_news_articles` that returns a list of dictionaries, where each dictionary has this shape:\n",
    "\n",
    "```python\n",
    "{\n",
    "    'title': 'The article title',\n",
    "    'content': 'The article content',\n",
    "    'category': 'business' # for example\n",
    "}```\n",
    "\n",
    "Hints:\n",
    "\n",
    "  a. Start by inspecting the website in your browser. Figure out which elements will be useful.\n",
    "  \n",
    "  b. Start by creating a function that handles a single article and produces a dictionary like the one above.\n",
    "  \n",
    "  c. Next create a function that will find all the articles on a single page and call the function you created in the last step for every article on the page.\n",
    "  \n",
    "  d. Now create a function that will use the previous two functions to scrape the articles from all the pages that you need, and do any additional processing that needs to be done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Bonus: cache the data\n",
    "\n",
    "Write your code such that the acquired data is saved locally in some form or fashion. Your functions that retrieve the data should prefer to read the local data instead of having to make all the requests everytime the function is called. Include a boolean flag in the functions to allow the data to be acquired \"fresh\" from the actual sources (re-writing your local cache)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
